---
author: izabela
secondAuthor: rafal-w
tags:
  - bright story
date: 2024-05-27T12:50:52.485Z
meaningfullyUpdatedAt: 2024-05-27T12:50:52.506Z
slug: coffee-ai-rafal-fullstack
title: Tasting Coffee, Coding AI. Meet Rafa≈Ç ‚Äì A Fullstack Developer
layout: post
image: /images/brightstoryrafalw.png
hidden: false
comments: true
published: true
language: en
---
Check out Rafa≈Ç‚Äôs journey to becoming an AI development specialist and discover which niche still hasn‚Äôt been addressed by AI. Also, learn how to explore coffee taste with just one sip.

<div className="image">![fullstack developer's story](/images/brightstoryrafalwgrid.png "fullstack developer's story")</div>

## Your passion for new technology started when you built your computer at 13. Tell us more about that experience.

I dreamt about having a better computer than the one I had at home. I wanted to build a computer from scratch, and **I managed to assemble most of the parts with some help from my parents**. I had to read tech documentation, and that‚Äôs how it all started. Years later, I still read the documentation. üôÇ

When I had this computer, I got deep into the gaming community. **I started creating simple webpages based on CMS platforms like WordPress**. Then I began **building game servers**. Those were times when game creators were more open to the community; you could add lots of mods and run your own servers. You could even earn some money from it.

Then, in technical school, I followed my passion for informatics and explored web development and basic frontend skills. I went to college to study Applied Computer Science, and that‚Äôs when programming truly began for me. **Studies forced me to learn some older languages like C++**, yet I quickly started to appreciate that. **Knowing these ‚Äúclunky‚Äù languages made it easier to switch to other technologies and enjoy their simplicity**. Obviously, my studies didn‚Äôt give me all the knowledge I needed, especially regarding working in a team with Git and CI/CD tools.

## How did your and Bright Inventions‚Äô paths cross?

It was 2 years ago when I was working at a software development agency, but my project ended and I was devastated because I enjoyed working with that team. **Eventually, Agata (a recruiter) reached out to me on LinkedIn**. It wasn‚Äôt anything new, but her message stood out because **she was very transparent about the company, projects, and clients I could work for**. That‚Äôs not always the case when you talk to recruiters. Also, at Bright Inventions, I had the chance to work with a tech stack I was keen on, including Node.js and NestJS.

**I actually wanted to join Bright Inventions after the initial screening with Agata. I was already super excited about this job opportunity.**

<div className="image">![team retreat](/images/rafal_team_retreat.png "A team retreat in the center of Gdansk.")</div>

<center> A team retreat in the center of Gdansk. </center>

## You are one of our AI development specialists. What was your research process and how did you gain knowledge about AI?

The entire AI research group at Bright Inventions focused on **exploring large language models (LLMs) and frameworks, along with concrete solutions such as building vector databases and using them with embeddings, to tailor AI to specific use cases**. This exploration led us to discover LangChain. **LangChain has extensive documentation**, which has been incredibly helpful.

We also read numerous blog posts, watched various videos, and listened to podcasts, although we found that this content quickly needed to be updated. **Therefore, documentation has proven to be the best source of information**. While other content was useful, it primarily served a supporting role in our research process.

## What is the skillset for a software developer who wants to specialize in AI implementation?

**Knowing Python is key**, as it leads the way in languages used for AI development. **Understanding prompt engineering is also important**. You need to read extensively about how models accept prompts, how they analyze them, and how to construct effective prompts. 

Additionally, it's crucial to **understand what various models can truly offer**. Understanding how models work and knowing the various models available on the market is essential for choosing the right one for our use case, especially when we have a strict budget. Fortunately, there are **tools like PromptFoo that can help us assess the costs our solution will generate**.

## What is more effective and affordable for a company that wants to implement generative AI: model training or enhancing prompt engineering?

I recommend prompt engineering. Model training requires more expertise, which increases the budget and resources needed. Additionally, often you have to pay extra for a model that allows for training. Usually, **creating a new prompt with a wider context to generate better results is less expensive compared to model training**.

It's not only about prompt engineering though. Building vector databases can also be more affordable than training models.

<div className="image">![quote](/images/rafal_w_prompt.png "quote")</div>

## What trends do you see in the implementation of generative AI?

I‚Äôve noticed a need that still hasn‚Äôt been fully addressed by generative AI. **We still lack models that recognize specific items from pictures or understand voice prompts**. Using written prompts is quite common, yet what about other options?

I think the [medtech industry will benefit from image recognition models](/blog/top-trends-in-healthtech/#advanced-implementations-of-generative-ai-in-healthcare), for example, for medical imaging. AI can support lung cancer diagnostics based on thousands of X-ray images. This is just one of many possible utilizations.

<div className="image">![quote](/images/rafal_quote_ai.png "quote")</div>

## What are the differences between LLMs and SLMs? Are SLMs a serious alternative to LLMs?

Small Language Models (SLMs) are supposed to be trained on less amount of data, therefore, they require fewer computational resources compared to LLMs. *[Read more about [LLMs, SLMs, and all those AI buzzwords](/blog/ai-buzzwords-definitions/).]* Yet, that‚Äôs a theory.

We have tested SLMs on laptops for personal use, and their responses to simple questions were usually correct. However, when the questions became more complex, these models made mistakes. **Given the high cost of launching SLMs, it‚Äôs not an investment that generates the desired returns, especially compared to models offered by OpenAI API**. With OpenAI, we don‚Äôt need to set up our infrastructure; we only pay for the actual requests we make.

In terms of SLMs, there have been situations where some models were not accessible through providers like AWS and Azure, **meaning you have to set up and manage the infrastructure and bear all associated costs**.

Therefore, I would consider whether SLMs are the right models, as they might not deliver the expected results.

<div className="image">![travelling](/images/rafal_travelling.png "travelling")</div>