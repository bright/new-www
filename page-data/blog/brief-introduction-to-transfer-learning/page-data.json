{"componentChunkName":"component---src-templates-post-template-tsx","path":"/blog/brief-introduction-to-transfer-learning","result":{"data":{"markdownRemark":{"html":"<p>In this item, I want to share with you the core idea behind transfer learning. We will solve a simple classification problem where we will try to correctly classify surfing, windsurfing and kitesurfing images but you can easily solve different problems relying on described steps</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/9cfce0b3c0e406f9ba6044688a13dfc1/0f98f/1.jpg\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 75%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAPABQDASIAAhEBAxEB/8QAGAAAAgMAAAAAAAAAAAAAAAAAAAIBAwT/xAAVAQEBAAAAAAAAAAAAAAAAAAAAAf/aAAwDAQACEAMQAAABzPW0BIv/xAAZEAADAQEBAAAAAAAAAAAAAAABAhEAEiH/2gAIAQEAAQUC7ahvDSWuXvG3/8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAwEBPwE//8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAgEBPwE//8QAHBAAAgICAwAAAAAAAAAAAAAAAAExMgIRITOR/9oACAEBAAY/Aro7UXXg+FsjEhH/xAAbEAEAAwADAQAAAAAAAAAAAAABABEhUWGBkf/aAAgBAQABPyFztZthNDSvMFgbuC340pM91iau2f/aAAwDAQACAAMAAAAQvM//xAAVEQEBAAAAAAAAAAAAAAAAAAABEP/aAAgBAwEBPxBZ/8QAFREBAQAAAAAAAAAAAAAAAAAAARD/2gAIAQIBAT8QCf/EABwQAQADAAMBAQAAAAAAAAAAAAEAESExUWGBkf/aAAgBAQABPxANsAAQv77HwIFoZ4xt2EBt/YipmqtmCuwDEicaMvqKHHXV1weT/9k='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"1\"\n        title=\"1\"\n        src=\"/static/9cfce0b3c0e406f9ba6044688a13dfc1/1c72d/1.jpg\"\n        srcset=\"/static/9cfce0b3c0e406f9ba6044688a13dfc1/a80bd/1.jpg 148w,\n/static/9cfce0b3c0e406f9ba6044688a13dfc1/1c91a/1.jpg 295w,\n/static/9cfce0b3c0e406f9ba6044688a13dfc1/1c72d/1.jpg 590w,\n/static/9cfce0b3c0e406f9ba6044688a13dfc1/a8a14/1.jpg 885w,\n/static/9cfce0b3c0e406f9ba6044688a13dfc1/fbd2c/1.jpg 1180w,\n/static/9cfce0b3c0e406f9ba6044688a13dfc1/0f98f/1.jpg 1920w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span></p>\n<p>Transfer learning is a very important and broad research problem. In general, it relies on transferring domain knowledge from one solved task to another unsolved one (but somehow related to the solved task). Consider following educational example - let's say you know how to ride a bike and you'd like to learn how to ride a scooter then it should be easier as there are some common principles like knowing that probably you should hold handlebar. Another example - if you know how to code then probably you are capable of fixing your auntie's computer, right? </p>\n<p>Here we will focus on the usage of transfer learning in computer vision problems. We will take advantage of one of the models with clever architectures (ResNet, MobileNet, Inception, etc.) that were trained on ImageNet dataset. ImageNet consists of enormous amount of images and each labeled with one of 1000 classes of various kind (e.g. <code>black widow</code> , <code>cassette player</code>  or <code>containership</code> but I can't see anything related to <code>surfing</code>). Those models are doing extremely well in dealing with recognizing classes on the provided image. Using pre-trained models would be especially beneficial when you have a very limited dataset. It may be even impossible to get a well-performing network from scratch. We can say that such models consist of 2 parts - feature extractor and classifier. We want to utilize feature extractor and replace classifier as we will classify 3 different classes instead of 1000. We want to keep feature extractor, especially first layers due to way convolutional layers work - they learn hierarchical representation and that means first layer will learn to find very general features like vertical or horizontal lines, next layers may learn something more complex like circles and so on. The last layers will be most elaborate and that's fine as long as our problem is similar to problem solved with a pre-trained model, if not then still we can benefit from such model by for example unfreezing some fraction of the layers.</p>\n<h3>Prepare dataset</h3>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/90f811128156aa31ed395277e6473a0c/0f98f/2.jpg\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 66.89189189189189%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAANABQDASIAAhEBAxEB/8QAGAAAAgMAAAAAAAAAAAAAAAAAAAQBAgX/xAAVAQEBAAAAAAAAAAAAAAAAAAACAf/aAAwDAQACEAMQAAABL5jwShJT/8QAGRABAQADAQAAAAAAAAAAAAAAAQIAESES/9oACAEBAAEFAp3LRjNKcw34p7//xAAVEQEBAAAAAAAAAAAAAAAAAAAREP/aAAgBAwEBPwFZ/8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAgEBPwE//8QAGRAAAwADAAAAAAAAAAAAAAAAAAERAhAh/9oACAEBAAY/AljEcKUTuv/EABsQAAIDAQEBAAAAAAAAAAAAAAABETFRQSFx/9oACAEBAAE/IcgLYyJS78HnWErJ7A7rwbwcuX9R/9oADAMBAAIAAwAAABAQz//EABURAQEAAAAAAAAAAAAAAAAAAAAR/9oACAEDAQE/EBH/xAAWEQEBAQAAAAAAAAAAAAAAAAABABH/2gAIAQIBAT8QQI2//8QAHBAAAgMBAAMAAAAAAAAAAAAAATEAESFRQWGR/9oACAEBAAE/EGX0yoHfGOZZ6EmPUsQ14ycsDFcuWwpv0uFlkrsBM//Z'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"2\"\n        title=\"2\"\n        src=\"/static/90f811128156aa31ed395277e6473a0c/1c72d/2.jpg\"\n        srcset=\"/static/90f811128156aa31ed395277e6473a0c/a80bd/2.jpg 148w,\n/static/90f811128156aa31ed395277e6473a0c/1c91a/2.jpg 295w,\n/static/90f811128156aa31ed395277e6473a0c/1c72d/2.jpg 590w,\n/static/90f811128156aa31ed395277e6473a0c/a8a14/2.jpg 885w,\n/static/90f811128156aa31ed395277e6473a0c/fbd2c/2.jpg 1180w,\n/static/90f811128156aa31ed395277e6473a0c/0f98f/2.jpg 1920w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span></p>\n<p>We need to create a dataset that will be used for solving our problem. If you don't have a dataset then you can just google for some of the widely available crawlers fetching images from google images or rely on services for that like Microsoft's <code>Bing Image Search API</code> (<a href=\"https://www.pyimagesearch.com/2018/04/09/how-to-quickly-build-a-deep-learning-image-dataset/\">great tutorial on creating dataset</a>). I'll go with Bing Image Search API.</p>\n<p>I've fetched 90 images of windsurfing, 82 of kitesurfing, and 98 of surfing. They are separated and the number of images of each class isn't equal but overall that's good enough.</p>\n<p> I've stored them accordingly in <code>dataset/windsurfing</code>, <code>dataset/kitesurfing</code>, <code>dataset/surfing</code>. </p>\n<p>Plot some images:</p>\n<pre><code class=\"language-python\">import glob, random, os\nfrom keras.preprocessing import image\n\nbase_path = \"dataset\"\nimg_list = glob.glob(os.path.join(base_path, '*/*.jpg'))\n\nfor i, img_path in enumerate(random.sample(img_list, 6)):\n    img = image.load_img(img_path, target_size=(IMG_SIZE, IMG_SIZE))\n    img = image.img_to_array(img, dtype=np.uint8)\n\n    plt.subplot(2, 3, i+1)\n    plt.imshow(img.squeeze())\n</code></pre>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 383px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/8f0fb4429dfe7bea6396c54fdfc7530d/d0c94/3.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 65.54054054054055%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAANCAYAAACpUE5eAAAACXBIWXMAAAsTAAALEwEAmpwYAAADjElEQVQ4yyWTW0+bBQCG+weM8cLEuxmTbYkXJjqNF0ZNtmZGJ1FwzM0KCSiwpcgYgQ2GTBQHbgPZlqmcAiMDCm5y2mBkdjjIKIe29Py1paVfW0pPfLRlfBwSmY/ZuHhvnzxv3ryKpzs7LEfi6C0+TI4gFsGP3eknGJJIpFIsSmv4kzJi4glicp3F1SdIqwkWRS9i0Pc8/iURr+hhXV5HAWBzhcj9fgB13X2Kawe42DTOwIMFpPUtOjxJbsf/4y8J+qI79Cz9SzC6Ql1TO92j42jGxqlp7qSs4TfsC14Um5syNkHkUtsUta3/0NBloHVIQHPPQCgmMRHdpMcXpW7awFXXMg3zXgSvj/qbg0zZg9we0vLzHz18XlrLnFVAsb29jd3hoP5GB5W/XKOwqprf27uZejRDKB5ndiVGx9wc6pvXuezSc3ZiBLcoMmGwMecSqfi1kcIrV3g/Px+d2bxb+aHJzEtfqUgrLkFZcIK23i76W9vxLAW4oOvnwuwQP+iHqJwd5Ox4L8FYBJ3FRXFjPR8V5XAgK509aYeYNOpRyKkUY7N60mpOox1uZ3q0n7sdrZwrKEDwuOicGaTbMsIt4z16rWPcGLuFc8GNVqen6OJPHD+j5uuyM3ymPoVJEHYNw9EoYmgJt8eJVXDjXPCgN5lIJpPE4iuEIxGcLvfz1W0OB4nEs5UDLPqX0BvNROOrGM02Umtru0CPz0N7XwctnS00d7XRommlXdOGlEjgDqeIb0NsC5ZlCK49JbYi0X1/Gs1DC3cmHPRozbQO6xBD0V2gcW6KY18o0VyvoiJTyVHlfr798gOcbhdjMwY88XW0Bis6l59Jq5dAKMykO0z/jIDWaKPkWjOH8k5jtAsoNmWZielpTlado7vxRyrS08jOziCnMJ950zzKjE85mp9DRl4uh08c4Uj2MQSnQEjeQH35Kk2dbbybkcmbGSr0Ftuu4aTezOufZFGjVnFw/172vXOQj/PKCIXD5BaXk1d6npNVdRz/7hSHM9OJRCIMP5pCmZPPN+WVqErKUZVVY3W6UWxsyAwOjfDCy/t47+23eHXPa7z4yl7eOPAhbo+XO9rHjOrm6XvwmD//1tHcO4TRZKao5hI5FdVklZ5HVVJBXmUNdrdn11CSJPyiD7PFgsVixrfowWDQI8sycUkiEovj9fnY2NrCvfDsszK+QIBAaBmz1YaUSGI0W0ilUvwPMEQoRTsqk/gAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"3\"\n        title=\"3\"\n        src=\"/static/8f0fb4429dfe7bea6396c54fdfc7530d/d0c94/3.png\"\n        srcset=\"/static/8f0fb4429dfe7bea6396c54fdfc7530d/12f09/3.png 148w,\n/static/8f0fb4429dfe7bea6396c54fdfc7530d/e4a3f/3.png 295w,\n/static/8f0fb4429dfe7bea6396c54fdfc7530d/d0c94/3.png 383w\"\n        sizes=\"(max-width: 383px) 100vw, 383px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span></p>\n<p>Split data into training (80%) and testing (20%) set. With ImageDataGenerator we can normalise images by setting value for each pixel between <code>0</code> and <code>1</code> - original value with range <code>0</code> to <code>255</code> would make it much harder for a network to converge. </p>\n<pre><code class=\"language-python\">from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\ndata_gen = ImageDataGenerator(\n    rescale=1./255,\n    validation_split=0.2\n)\n\ntrain_generator = data_gen.flow_from_directory(\n    base_path,\n    target_size=(IMG_SIZE, IMG_SIZE),\n    class_mode='categorical',\n    subset='training',\n    seed=37\n)\n\nvalidation_generator = data_gen.flow_from_directory(\n    base_path,\n    target_size=(IMG_SIZE, IMG_SIZE),\n    class_mode='categorical',\n    subset='validation',\n    seed=37\n)\n</code></pre>\n<h3>Download model with pre-trained weights</h3>\n<p>Then we download the model with pre-trained weights. Let's pick MobileNetV2. <code>include_top</code> should be set to <code>False</code> because we don't want its classifier which is the last layer with 1000 classes compatible with ImageNet - we need to create our own classifier. Besides, let's freeze weights of a downloaded model so that we will train just our own classifier layers and downloaded weights will remain the same. </p>\n<pre><code class=\"language-python\">base_model = tf.keras.applications.MobileNetV2(\n    input_shape=IMG_SHAPE,\n    include_top=False,\n    weights='imagenet'\n)\n\nbase_model.trainable = False\n</code></pre>\n<p>Create custom layers so that last one fits our outputs which is 3 neurons (respectively for surfing, windsurfing, kitesurfing)</p>\n<pre><code class=\"language-python\">model = tf.keras.Sequential([\n    base_model,\n    keras.layers.GlobalAveragePooling2D(),\n    keras.layers.Dense(64, activation='relu'),\n    keras.layers.Dense(3, activation='sigmoid')\n])\n\nmodel.compile(lr=0.005, loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\nmodel.summary()\n</code></pre>\n<h3>Train and validate</h3>\n<pre><code class=\"language-python\">batch_size = 16\nepochs = 10\nsteps_per_epoch = train_generator.n // batch_size\nvalidation_steps = validation_generator.n // batch_size\n\nhistory = model.fit_generator(\n    train_generator, \n    steps_per_epoch = steps_per_epoch,\n    epochs=epochs,                             \n    validation_data=validation_generator, \n    validation_steps=validation_steps\n)\n</code></pre>\n<p>Train the network for a few epochs and check how validation loss and accuracy behave in order to prevent overfitting. Dataset is pretty small and after 10 epochs model reaches ~90% of validation accuracy. </p>\n<p>One of the further improvements you can do is to unfreeze some of the layers and train a model for a few more epochs.</p>\n<p>Then save your model to file so you can use it later. </p>\n<pre><code class=\"language-python\">tf.keras.models.save_model(model, \"blog_model.h5\")\n</code></pre>\n<p>I highly encourage you to take advantage of created model and use it in your android application (<a href=\"https://brightinventions.pl/blog/image-classification-tensorflowlite-android/\">check out my tutorial on that</a>). To transform such model to be mobile friendly convert it to TensorFlow Lite and you are ready to go. However <a href=\"https://brightinventions.pl/blog/are-we-ready-for-deep-learning-on-mobile-devices/\">most of architectures can't be used directly on mobile devices</a> due to lack of support for some operators as well as memory constraints but if you go with some that are simple enough or were intended for embedded devices like MobileNet then it shouldn't be a problem.</p>\n<pre><code class=\"language-python\">converter = tf.lite.TFLiteConverter.from_keras_model_file(\"blog_model.h5\")\ntflite_model = converter.convert()\nopen(\"blog_model.tflite\", \"wb\").write(tflite_model)\n</code></pre>","excerpt":"In this item, I want to share with you the core idea behind transfer learning. We will solve a simple classification problem where we willâ€¦","frontmatter":{"slug":null,"title":"Brief introduction to transfer learning","description":null,"author":"radeks","tags":["deep learning","image classification","transfer learning"],"date":"2020-05-18T22:00:00.000Z","image":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#e8e8e8","images":{"fallback":{"src":"/static/693c19abb71e4870a536e01ca2704d8a/61616/brief-introduction-to-transfer-learning-top.jpg","srcSet":"/static/693c19abb71e4870a536e01ca2704d8a/56cdc/brief-introduction-to-transfer-learning-top.jpg 692w,\n/static/693c19abb71e4870a536e01ca2704d8a/b2de5/brief-introduction-to-transfer-learning-top.jpg 1384w,\n/static/693c19abb71e4870a536e01ca2704d8a/61616/brief-introduction-to-transfer-learning-top.jpg 2768w","sizes":"(min-width: 2768px) 2768px, 100vw"},"sources":[{"srcSet":"/static/693c19abb71e4870a536e01ca2704d8a/e6263/brief-introduction-to-transfer-learning-top.webp 692w,\n/static/693c19abb71e4870a536e01ca2704d8a/bc987/brief-introduction-to-transfer-learning-top.webp 1384w,\n/static/693c19abb71e4870a536e01ca2704d8a/959c9/brief-introduction-to-transfer-learning-top.webp 2768w","type":"image/webp","sizes":"(min-width: 2768px) 2768px, 100vw"}]},"width":2768,"height":1848.0000000000002}}}},"timeToRead":5,"fileAbsolutePath":"/home/runner/work/new-www/new-www/src/mdData/blog/2020-05-19-brief-introduction-to-transfer-learning.md"},"site":{"siteMetadata":{"siteUrl":"https://brightinventions.pl"}}},"pageContext":{"fileAbsolutePath":"/home/runner/work/new-www/new-www/src/mdData/blog/2020-05-19-brief-introduction-to-transfer-learning.md"}},"staticQueryHashes":["2189233960","3181594896"]}